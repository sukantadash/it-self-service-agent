{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717ebb93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_stack_client==0.3.0 in /opt/app-root/lib64/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: fire in /opt/app-root/lib64/python3.12/site-packages (0.7.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (4.12.0)\n",
      "Requirement already satisfied: click in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (8.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (2.3.3)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (3.0.52)\n",
      "Requirement already satisfied: pyaml in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (25.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (2.12.5)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (2.32.5)\n",
      "Requirement already satisfied: rich in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (14.2.0)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (1.3.1)\n",
      "Requirement already satisfied: termcolor in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.5.0->llama_stack_client==0.3.0) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.3.0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.3.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_stack_client==0.3.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.3.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.3.0) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama_stack_client==0.3.0) (1.17.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.12/site-packages (from prompt-toolkit->llama_stack_client==0.3.0) (0.2.14)\n",
      "Requirement already satisfied: PyYAML in /opt/app-root/lib64/python3.12/site-packages (from pyaml->llama_stack_client==0.3.0) (6.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client==0.3.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client==0.3.0) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client==0.3.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client==0.3.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack_client==0.3.0) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_stack_client==0.3.0 fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb99dee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from llama_stack_client import RAGDocument, LlamaStackClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d375b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "client = LlamaStackClient(base_url=\"http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9231d38d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Model(identifier='llama-17b/llama-4-scout-17b-16e-w4a16', metadata={}, api_model_type='llm', provider_id='llama-17b', type='model', provider_resource_id='llama-4-scout-17b-16e-w4a16', model_type='llm'),\n",
       " Model(identifier='sentence-transformers/all-MiniLM-L6-v2', metadata={'embedding_dimension': 384.0}, api_model_type='embedding', provider_id='sentence-transformers', type='model', provider_resource_id='all-MiniLM-L6-v2', model_type='embedding'),\n",
       " Model(identifier='sentence-transformers/nomic-ai/nomic-embed-text-v1.5', metadata={'embedding_dimension': 768.0, 'default_configured': True}, api_model_type='embedding', provider_id='sentence-transformers', type='model', provider_resource_id='nomic-ai/nomic-embed-text-v1.5', model_type='embedding')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ede4bb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321/v1/vector_stores \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SyncOpenAICursorPage[VectorStore](data=[], has_more=False, last_id=None, object='list', first_id=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_stores = client.vector_stores.list()\n",
    "vector_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b8a9b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321/v1/providers \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider ID: llama-3b\n",
      "Provider Type: remote::vllm\n",
      "--------------------\n",
      "Provider ID: llama-17b\n",
      "Provider Type: remote::vllm\n",
      "--------------------\n",
      "Provider ID: deepseek\n",
      "Provider Type: remote::vllm\n",
      "--------------------\n",
      "Provider ID: sentence-transformers\n",
      "Provider Type: inline::sentence-transformers\n",
      "--------------------\n",
      "Provider ID: pgvector\n",
      "Provider Type: remote::pgvector\n",
      "--------------------\n",
      "Provider ID: meta-reference\n",
      "Provider Type: inline::meta-reference\n",
      "--------------------\n",
      "Provider ID: meta-reference\n",
      "Provider Type: inline::meta-reference\n",
      "--------------------\n",
      "Provider ID: meta-reference-files\n",
      "Provider Type: inline::localfs\n",
      "--------------------\n",
      "Provider ID: huggingface\n",
      "Provider Type: remote::huggingface\n",
      "--------------------\n",
      "Provider ID: localfs\n",
      "Provider Type: inline::localfs\n",
      "--------------------\n",
      "Provider ID: basic\n",
      "Provider Type: inline::basic\n",
      "--------------------\n",
      "Provider ID: llm-as-judge\n",
      "Provider Type: inline::llm-as-judge\n",
      "--------------------\n",
      "Provider ID: braintrust\n",
      "Provider Type: inline::braintrust\n",
      "--------------------\n",
      "Provider ID: brave-search\n",
      "Provider Type: remote::brave-search\n",
      "--------------------\n",
      "Provider ID: tavily-search\n",
      "Provider Type: remote::tavily-search\n",
      "--------------------\n",
      "Provider ID: rag-runtime\n",
      "Provider Type: inline::rag-runtime\n",
      "--------------------\n",
      "Provider ID: model-context-protocol\n",
      "Provider Type: remote::model-context-protocol\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Fetch all providers\n",
    "providers = client.providers.list()\n",
    "\n",
    "# Display details for each provider\n",
    "for provider in providers:\n",
    "    print(f\"Provider ID: {provider.provider_id}\")\n",
    "    print(f\"Provider Type: {provider.provider_type}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe8c6e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_client',\n",
       " '_delete',\n",
       " '_get',\n",
       " '_get_api_list',\n",
       " '_patch',\n",
       " '_post',\n",
       " '_put',\n",
       " '_sleep',\n",
       " 'create',\n",
       " 'delete',\n",
       " 'file_batches',\n",
       " 'files',\n",
       " 'list',\n",
       " 'retrieve',\n",
       " 'search',\n",
       " 'update',\n",
       " 'with_raw_response',\n",
       " 'with_streaming_response']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(client.vector_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce65e8d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321/v1/vector_stores \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_stack_client.types.vector_store import VectorStore\n",
    "for vs in client.vector_stores.list():\n",
    "    print(type(vs))\n",
    "    print(vs)\n",
    "    print(vs.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60049f21-7fda-40a9-830f-39f5fb6cde2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321/v1/vector_stores \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SyncOpenAICursorPage[VectorStore](data=[], has_more=False, last_id=None, object='list', first_id=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.vector_stores.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb5ae8-5163-42e5-b3e3-c07c241d0033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
