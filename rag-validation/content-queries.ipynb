{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e55af97",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_stack_client==0.3.0 in /opt/app-root/lib64/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (4.12.0)\n",
      "Requirement already satisfied: click in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (8.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (1.9.0)\n",
      "Requirement already satisfied: fire in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (0.7.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (2.3.3)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (3.0.52)\n",
      "Requirement already satisfied: pyaml in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (25.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (2.12.5)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (2.32.5)\n",
      "Requirement already satisfied: rich in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (14.2.0)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (1.3.1)\n",
      "Requirement already satisfied: termcolor in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.3.0) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.5.0->llama_stack_client==0.3.0) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.3.0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.3.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_stack_client==0.3.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.3.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.3.0) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.3.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama_stack_client==0.3.0) (1.17.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.12/site-packages (from prompt-toolkit->llama_stack_client==0.3.0) (0.2.14)\n",
      "Requirement already satisfied: PyYAML in /opt/app-root/lib64/python3.12/site-packages (from pyaml->llama_stack_client==0.3.0) (6.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client==0.3.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client==0.3.0) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client==0.3.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client==0.3.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack_client==0.3.0) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_stack_client==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca673f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from llama_stack_client import Agent, AgentEventLogger, LlamaStackClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd2b53f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "client = LlamaStackClient(base_url=\"http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d479c7b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "models\n",
    "model_id = next(m.identifier for m in models if m.model_type == \"llm\")\n",
    "embedding = next(m for m in models if m.model_type == \"embedding\")\n",
    "embedding_model_id = embedding.identifier\n",
    "embedding_dimension = int(embedding.metadata[\"embedding_dimension\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2fcd77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack-with-config-service.llama-stack.svc.cluster.local:8321/v1/vector_stores \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m pg_store = \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m      2\u001b[39m     (vs \u001b[38;5;28;01mfor\u001b[39;00m vs \u001b[38;5;129;01min\u001b[39;00m client.vector_stores.list() \u001b[38;5;28;01mif\u001b[39;00m vs.metadata[\u001b[33m'\u001b[39m\u001b[33mprovider_id\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpgvector\u001b[39m\u001b[33m\"\u001b[39m), \n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vector_db_id = \u001b[43mpg_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(pg_store)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "pg_store = next(\n",
    "    (vs for vs in client.vector_stores.list() if vs.metadata['provider_id'] == \"pgvector\"), \n",
    "    None\n",
    ")\n",
    "vector_db_id = pg_store.id\n",
    "print(pg_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dec1c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(embedding_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e46428",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e2b47-9c1a-43c2-9fae-cc0e250767a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.vector_dbs.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f5314-8b3e-4fb7-a80f-e02b9411ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector_db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e403f-43ad-4350-8788-308b6a981fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What benefits do the ingested passages provide for retrieval?\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=model_id,\n",
    "    input=query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [vector_db_id],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"Responses API result:\", getattr(response, \"output_text\", response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdbdb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What benefits do the ingested passages provide for retrieval?\"\n",
    "result = client.tool_runtime.rag_tool.query(\n",
    "    vector_db_ids=[vector_db_id],\n",
    "    content=query,\n",
    ")\n",
    "print(\"Low-level query result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816dacb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create an Agent for conversational RAG queries\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=\"You are a helpful assistant that can use tools to answer questions.\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"builtin::rag/knowledge_search\",\n",
    "            \"args\": {\"vector_db_ids\": [vector_db_id]},\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt = \"How do you do great work?\"\n",
    "print(\"Prompt>\", prompt)\n",
    "\n",
    "# Create a session and run a streaming turn\n",
    "session_id = agent.create_session(\"rag_session\")\n",
    "response = agent.create_turn(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    session_id=session_id,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Log and print the agent's response\n",
    "for log in AgentEventLogger().log(response):\n",
    "    log.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a206d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example RAG query for one-off lookups\n",
    "query = \"What is a Data Science Workflow?\"\n",
    "result = client.tool_runtime.rag_tool.query(\n",
    "    vector_db_ids=[vector_db_id],\n",
    "    content=query,\n",
    ")\n",
    "print(\"Low-level query result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2063a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example RAG query for one-off lookups\n",
    "query = \"What are the default workbench images provided by RHOAI?\"\n",
    "result = client.tool_runtime.rag_tool.query(\n",
    "    vector_db_ids=[vector_db_id],\n",
    "    content=query,\n",
    ")\n",
    "print(\"Low-level query result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876caedf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create an Agent for conversational RAG queries\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"builtin::rag/knowledge_search\",\n",
    "            \"args\": {\"vector_db_ids\": [vector_db_id]},\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt = \"What are the default workbench images provided by RHOAI?\"\n",
    "print(\"Prompt>\", prompt)\n",
    "\n",
    "# Create a session and run a streaming turn\n",
    "session_id = agent.create_session(\"rag_session\")\n",
    "response = agent.create_turn(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    session_id=session_id,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Log and print the agent's response\n",
    "for log in AgentEventLogger().log(response):\n",
    "    log.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fe42f-1379-41d2-81f5-08901c80f0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
